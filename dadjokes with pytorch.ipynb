{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from spacy.util import minibatch\n",
    "from torch import nn\n",
    "from pytorch_transformers import *\n",
    "from sklearn.model_selection import train_test_split \n",
    "from datetime import datetime as dt\n",
    "from dateutil import tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencizer', 'pytt_wordpiecer', 'pytt_tok2vec']\n"
     ]
    }
   ],
   "source": [
    "is_using_gpu = spacy.prefer_gpu()\n",
    "if is_using_gpu:\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "\n",
    "nlp = spacy.load('en_pytt_robertabase_lg')\n",
    "print(nlp.pipe_names) # [\"sentencizer\", \"pytt_wordpiecer\", \"pytt_tok2vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@inproceedings{ott2019fairseq,\n",
    "  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},\n",
    "  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},\n",
    "  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},\n",
    "  year = {2019},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'dadjokes-subreddit-archive/data_dadjokes.csv'\n",
    "jokes_path = 'dadjokes-subreddit-archive/data_jokes.csv'\n",
    "\n",
    "jokes = pd.read_csv(jokes_path, na_values=[\"[deleted]\", \"\",'N/A'], index_col=0, sep='|')\n",
    "dj = pd.read_csv(csv_path, na_values=[\"[deleted]\", \"\",'N/A'], index_col=0, sep='|')\n",
    "dj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dj.isna().sum())\n",
    "print(jokes.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df):\n",
    "    df.title.fillna('', inplace=True)\n",
    "    df.selftext.fillna('', inplace=True)\n",
    "    return df\n",
    "\n",
    "dj = fill_na(dj)\n",
    "jokes = fill_na(jokes)\n",
    "print(dj.isna().sum())\n",
    "print(jokes.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dj.score, dj.num_comments);\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Total Comments')\n",
    "plt.title('Score vs. Number of Comments on\\nSubmissions in /r/dadjokes')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(jokes.score, jokes.num_comments);\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Total Comments')\n",
    "plt.title('Score vs. Number of Comments on\\nSubmissions in /r/jokes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Total Comments')\n",
    "plt.ylabel('Number of Submissions')\n",
    "plt.title('Submissions by Number of Comments\\nin /r/dadjokes')\n",
    "plt.hist(dj.num_comments, bins=[0,5,20,100,500,1500]);\n",
    "plt.show()\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Total Comments')\n",
    "plt.ylabel('Number of Submissions')\n",
    "plt.title('Submissions by Number of Comments\\nin /r/jokes')\n",
    "plt.hist(jokes.num_comments, bins=[0,5,20,50,100,500,1500]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of Submissions')\n",
    "plt.title('Submissions by Score (Upvotes) in /r/dadjokes')\n",
    "plt.hist(dj.score, bins=[0,5,20,100,500,40000]);\n",
    "plt.show()\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of Submissions')\n",
    "plt.title('Submissions by Score (Upvotes) in /r/jokes')\n",
    "plt.hist(jokes.score, bins=[0,5,20,100,500,40000]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes['is_crosspost'] = ~jokes['parent_createdUTC'].isna()\n",
    "jokes.groupby(by='is_crosspost').mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj['is_crosspost'] = ~dj['parent_createdUTC'].isna()\n",
    "dj.groupby(by='is_crosspost').mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crossposts receive significantly lower scores, num_comments than original posts in the dadjokes subreddit. This may be because viewers are easily redirected to the parent post to comments or upvote in other areas of reddit. However, the contents of the crossposted jokes (title and selftext) are pulled from the parent posts. Therefore crossposts will be analyzed separately when attempting to predict scores, num_comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dj = dj[~dj.is_crosspost].drop(columns=['parent_createdUTC', 'is_crosspost'])\n",
    "print(main_dj.shape)\n",
    "\n",
    "main_jokes = jokes[~jokes.is_crosspost].drop(columns=['parent_createdUTC', 'is_crosspost'])\n",
    "print(main_jokes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dj, test_dj = train_test_split(main_dj, test_size=0.2, random_state=42)\n",
    "print(f\"Training sample size: {len(train_dj)}\\nTesting sample size: {len(test_dj)}\")\n",
    "\n",
    "train_jokes, test_jokes = train_test_split(main_jokes, test_size=0.2, random_state=42)\n",
    "print(f\"Training sample size: {len(train_jokes)}\\nTesting sample size: {len(test_jokes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_num(val):\n",
    "    if val <= 1:\n",
    "        return 0\n",
    "    elif val <= 5:\n",
    "        return 1\n",
    "    elif val <= 20:\n",
    "        return 2\n",
    "    elif val <= 100:\n",
    "        return 3\n",
    "    elif val <= 500:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def make_categories(data):\n",
    "    data['score_cat'] = data['score'].apply(lambda x: cat_num(x))\n",
    "    data['comment_cat'] = data['num_comments'].apply(lambda x: cat_num(x))\n",
    "    return data    \n",
    "\n",
    "\n",
    "def prepare_text(data):\n",
    "    data.title = data.title.apply(lambda s: s.replace('&amp;#x200B;', ''))\n",
    "    data.selftext = data.selftext.apply(lambda s: s.replace('&amp;#x200B;', ''))\n",
    "    newlines = re.compile(r'(\\\\n)+')\n",
    "    #new_sent = re.compile(r'(\\w+:\\S*)')\n",
    "    empty = re.compile(r'\\s*')\n",
    "    data['joke'] = data.apply(lambda row: ' </s> </s> '.join([row['title'], row['selftext']])))), axis=1)\n",
    "    data['joke'] = ['<s> ' + ' </s> </s> '.join([j.strip() for j in new_sent.split(joke)\n",
    "                               if not empty.fullmatch(j)]) + ' </s>' for joke in jokelist]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dj = make_categories(train_dj)\n",
    "train_dj = prepare_text(train_dj)\n",
    "train_dj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dadjokes-subreddit-archive/dadjokes_train.txt', 'w') as jokes:\n",
    "    for joke in train_dj.joke:\n",
    "        jokes.write(joke+'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roberta.eval()\n",
    "\n",
    "def _rob_encode(df, col):\n",
    "    df[col + '_tokens'] = df[col].apply(lambda x: roberta.encode(x))\n",
    "    return df\n",
    "\n",
    "def roberta_encode(df):\n",
    "    df = _rob_encode(df, 'title')\n",
    "    df = _rob_encode(df, 'selftext')\n",
    "    return df\n",
    "\n",
    "train_dj = roberta_encode(train_dj)\n",
    "train_jokes = roberta_encode(train_jokes)\n",
    "train_dj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dj['input_ids'] = train_dj.joke.apply(lambda x: tokenizer.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dj['title_encoded'] = train_dj.title_doc.apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "train_dj['selftext_encoded'] = train_dj.selftext_doc.apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_ids)\n",
    "print(labels)\n",
    "print(outputs)\n",
    "print(loss)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dj['toolong'] = train_dj.input_ids.apply(lambda ids: len(ids)>512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = train_dj[train_dj['toolong']]\n",
    "print(len(long))\n",
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama = train_dj.loc['cjpxky']\n",
    "print(obama.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe([\"I like Mr. Water. Water is good? No? NO! Well... Whatever\\nuhat's that\", \"this...is good\"])\n",
    "for doc in docs:\n",
    "    for sent in doc.sents:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_detector.tokenize(\"I like Mr. Water. Water is good? No? NO! Well... Whatever\\nuhat's that\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
