{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "pytorch_roberta.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jojordan3/dad-joke-ai/blob/master/pytorch_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "z1O2teQfX-eN",
        "colab_type": "code",
        "outputId": "5828430e-964b-41c0-9aa2-f2e642f55ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install gputil\n",
        "!pip install spacy-pytorch-transformers[cuda100]\n",
        "!python -m spacy download en_pytt_robertabase_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=3191b17a5642ad2df8f34e0222601483961f003eb7dd18d86d658fcc2b1681d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Collecting spacy-pytorch-transformers[cuda100]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/46/3271586944ee5e0bd493df03b1ad189eb9ccdad1d2476aeb843b0d2f1b47/spacy_pytorch_transformers-0.4.0-py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (0.1.0)\n",
            "Requirement already satisfied: spacy<2.2.0,>=2.1.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (2.1.8)\n",
            "Requirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (0.6)\n",
            "Collecting torchcontrib<0.1.0,>=0.0.2 (from spacy-pytorch-transformers[cuda100])\n",
            "  Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n",
            "Collecting pytorch-transformers<1.3.0,>=1.2.0 (from spacy-pytorch-transformers[cuda100])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 9.7MB/s \n",
            "\u001b[?25hCollecting ftfy<6.0.0,>=5.0.0 (from spacy-pytorch-transformers[cuda100])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (1.1.0)\n",
            "Requirement already satisfied: cupy-cuda100>=5.0.0b4; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]) (5.4.0)\n",
            "Collecting thinc-gpu-ops<0.1.0,>=0.0.1; extra == \"cuda100\" (from spacy-pytorch-transformers[cuda100])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/ad/11ab80a24bcedd7dd0cfabaedba2ceaeca11f1aaeeff432a3d2e63ca7d02/thinc_gpu_ops-0.0.4.tar.gz (483kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 18.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (1.16.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (0.2.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (0.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (1.0.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (7.0.8)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (0.9.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (1.9.220)\n",
            "Collecting sacremoses (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/24/0b86f494d3a5c7531f6d0c77d39fd8f9d42e651244505d3d737e31db9a4d/sacremoses-0.0.33.tar.gz (802kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 34.6MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 47.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 37.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-pytorch-transformers[cuda100]) (0.1.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy-pytorch-transformers[cuda100]) (1.12.0)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy-pytorch-transformers[cuda100]) (0.4)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.220 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (1.12.220)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (0.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.220->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.220->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]) (0.15.2)\n",
            "Building wheels for collected packages: torchcontrib, ftfy, thinc-gpu-ops, sacremoses, regex\n",
            "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-cp36-none-any.whl size=7530 sha256=e7d0104c90b567b457bfeb6bc4fcb62bb2193c9292146750db52e452ec5ff971\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44553 sha256=ae0717d38f7b9f908eab4ddf798b754d00967d59fa13217710b222dc4b089ecd\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
            "  Building wheel for thinc-gpu-ops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thinc-gpu-ops: filename=thinc_gpu_ops-0.0.4-cp36-cp36m-linux_x86_64.whl size=220579 sha256=fbaca2d7228a4ff55fc3ba5e2d63dbba1c6d24ba588fab2c5add7d8353fb68ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/ba/a3/9af9f326ed0d75a4540378af64a05a0e42be39d9b8513f3aea\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.33-cp36-none-any.whl size=833106 sha256=5ad43963308842ff3774a7b2dc267a89611dac69cf456d20121a01a99e39e5ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/87/56/e40575cca30d12fee8875d523b8878b7aba866a9f03b2fd983\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609246 sha256=dc6ad86dfb333da867150d726c03d9420a3bf89d703000d15e8672a35bfd28f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built torchcontrib ftfy thinc-gpu-ops sacremoses regex\n",
            "Installing collected packages: torchcontrib, sacremoses, regex, sentencepiece, pytorch-transformers, ftfy, thinc-gpu-ops, spacy-pytorch-transformers\n",
            "Successfully installed ftfy-5.6 pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.33 sentencepiece-0.1.83 spacy-pytorch-transformers-0.4.0 thinc-gpu-ops-0.0.4 torchcontrib-0.0.2\n",
            "Collecting en_pytt_robertabase_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_pytt_robertabase_lg-2.1.0/en_pytt_robertabase_lg-2.1.0.tar.gz#egg=en_pytt_robertabase_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_pytt_robertabase_lg-2.1.0/en_pytt_robertabase_lg-2.1.0.tar.gz (291.9MB)\n",
            "\u001b[K     |████████████████████████████████| 291.9MB 1.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-pytt-robertabase-lg\n",
            "  Building wheel for en-pytt-robertabase-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-pytt-robertabase-lg: filename=en_pytt_robertabase_lg-2.1.0-cp36-none-any.whl size=295936801 sha256=ed8aa68e11690378538f0e0eaa8d5952d39371dd46d3a5cc5bf11f0515aa441f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ygodtqad/wheels/46/ec/e1/01b719774e9b2323e7263c0f93aacb40091e136d62aa071403\n",
            "Successfully built en-pytt-robertabase-lg\n",
            "Installing collected packages: en-pytt-robertabase-lg\n",
            "Successfully installed en-pytt-robertabase-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_pytt_robertabase_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRxthXX1kOCP",
        "colab_type": "text"
      },
      "source": [
        "RESTART runtime after download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GVprUtLbrM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import torch\n",
        "import cupy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "import unicodedata\n",
        "import GPUtil\n",
        "import spacy_pytorch_transformers\n",
        "import en_pytt_robertabase_lg\n",
        "\n",
        "from spacy_pytorch_transformers import PyTT_Language, PyTT_WordPiecer, PyTT_TokenVectorEncoder, PyTT_TextCategorizer\n",
        "from spacy_pytorch_transformers.util import cyclic_triangular_rate\n",
        "from tqdm import tqdm\n",
        "from spacy.util import minibatch\n",
        "from numpy.testing import assert_almost_equal\n",
        "from scipy.spatial import distance\n",
        "from google.colab import drive\n",
        "from wasabi import Printer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder as OHE\n",
        "from sklearn.compose import make_column_transformer\n",
        "from datetime import datetime as dt\n",
        "from datetime import timezone as tz\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FSLe1BnQwHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "064d1849-80bd-49e3-cca4-b77694b745c4"
      },
      "source": [
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive/My\\ Drive/data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE-PHeUWwkpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = '/gdrive/My Drive/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkLLx1KyX-eq",
        "colab_type": "code",
        "outputId": "b15b940a-ffbd-4914-f528-4d2e72e3b3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "is_using_gpu = spacy.prefer_gpu()\n",
        "def check_gpu(is_using_gpu):\n",
        "  if is_using_gpu:\n",
        "    print(\"Using GPU!\")\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "    print(\"GPU Usage\")\n",
        "    GPUtil.showUtilization()\n",
        "\n",
        "spacy.prefer_gpu()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWTpvnuXX-e2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_path = base_path + 'data_dadjokes.csv'\n",
        "\n",
        "dj = pd.read_csv(csv_path, na_values=[\"[deleted]\", None,'N/A', ' ', '[removed]', ''], index_col=None, sep='|')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PCyaau0912C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "7521fe37-cefd-450b-a980-1b0850cf68ed"
      },
      "source": [
        "print(dj.isna().sum())\n",
        "print(dj[dj.title.isna()].isna().sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id                        0\n",
            "createdUTC                0\n",
            "parent_createdUTC    159813\n",
            "author                14419\n",
            "title                     4\n",
            "selftext              14913\n",
            "score                     0\n",
            "num_comments              0\n",
            "dtype: int64\n",
            "id                   0\n",
            "createdUTC           0\n",
            "parent_createdUTC    4\n",
            "author               0\n",
            "title                4\n",
            "selftext             4\n",
            "score                0\n",
            "num_comments         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw4cEkL6_fuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "798ff70e-0797-40ad-889a-3726cb1c1239"
      },
      "source": [
        "dj.drop(index = dj.index[dj.title.isna()], inplace=True)\n",
        "\n",
        "dj.isna().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                        0\n",
              "createdUTC                0\n",
              "parent_createdUTC    159809\n",
              "author                14419\n",
              "title                     0\n",
              "selftext              14909\n",
              "score                     0\n",
              "num_comments              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTe6E8KlX-fK",
        "colab_type": "code",
        "outputId": "dc0218e8-d8b8-4596-8157-be3662b3fe3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "plt.scatter(dj.score, dj.num_comments);\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Total Comments')\n",
        "plt.title('Score vs. Number of Comments on\\nSubmissions in /r/dadjokes')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAElCAYAAADz3wVRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKHCIiEgmChwiIpLJ/wfX3H3t/+fn8QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK_hSoJ3X-fY",
        "colab_type": "code",
        "outputId": "ac185eef-cc21-4f70-e9ad-c2d74928a4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Total Comments')\n",
        "plt.ylabel('Number of Submissions')\n",
        "plt.title('Submissions by Number of Comments\\nin /r/dadjokes')\n",
        "plt.hist(dj.num_comments, bins=[0,1,3,10,50,dj.num_comments.max()]);\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEpCAYAAACJA7VtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhBbE8_qX-fe",
        "colab_type": "code",
        "outputId": "221fe555-2a8e-43cf-b872-97346e1113a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Number of Submissions')\n",
        "plt.title('Submissions by Score (Upvotes) in /r/dadjokes')\n",
        "plt.hist(dj.score, bins=[0,1,5,20,100,dj.score.max()]);\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEaCAYAAADDgSq4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbEqdIZAX-fw",
        "colab_type": "code",
        "outputId": "1cf66b1e-3bd0-43db-f02b-a96be98bbfa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "dj['is_crosspost'] = ~dj['parent_createdUTC'].isna()\n",
        "dj.groupby(by='is_crosspost').mean()    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>createdUTC</th>\n",
              "      <th>parent_createdUTC</th>\n",
              "      <th>score</th>\n",
              "      <th>num_comments</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_crosspost</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>1.494574e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>91.876991</td>\n",
              "      <td>3.318086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>1.544514e+09</td>\n",
              "      <td>1.543970e+09</td>\n",
              "      <td>2.560386</td>\n",
              "      <td>0.357488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                createdUTC  parent_createdUTC      score  num_comments\n",
              "is_crosspost                                                          \n",
              "False         1.494574e+09                NaN  91.876991      3.318086\n",
              "True          1.544514e+09       1.543970e+09   2.560386      0.357488"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNTOLjaZX-f2",
        "colab_type": "text"
      },
      "source": [
        "##### Crossposts receive significantly lower scores, num_comments than original posts in the dadjokes subreddit. This may be because viewers are easily redirected to the parent post to comments or upvote in other areas of reddit. However, the contents of the crossposted jokes (title and selftext) are pulled from the parent posts. Therefore crossposts will be analyzed separately when attempting to predict scores, num_comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V6HjVDUX-f3",
        "colab_type": "code",
        "outputId": "2ed20b3f-5a54-4604-ed5a-d1c63b23f2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "main_dj = dj[~dj.is_crosspost].drop(columns=['parent_createdUTC', 'is_crosspost'])\n",
        "print(main_dj.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159809, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmHWer8zX-f-",
        "colab_type": "code",
        "outputId": "4225a0da-f6e1-482a-e9b0-3888253bc709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "train_dj, test_dj = train_test_split(main_dj, test_size=0.2)\n",
        "print(f\"Training sample size: {len(train_dj)}\\nTesting sample size: {len(test_dj)}\")\n",
        "\n",
        "train_dj.reset_index(drop=True, inplace=True)\n",
        "test_dj.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training sample size: 127847\n",
            "Testing sample size: 31962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78LvtUsNX-gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_cats = [1, 5, 20, 100]\n",
        "comment_cats = [1, 3, 10, 50]\n",
        "newlines = re.compile(r'(\\\\n)|\\s+]')\n",
        "\n",
        "def _gettext(s):\n",
        "  if isinstance(s, str):\n",
        "    s = s.replace('&amp;#x200B;', '')\n",
        "    s = s.replace('&amp;', 'and')\n",
        "    s = newlines.sub(' ', s)\n",
        "  return s\n",
        "\n",
        "\n",
        "def prepare_text(data):\n",
        "    data['title_clean'] = data.title.apply(_gettext)\n",
        "    data['selftext_clean'] = data.selftext.apply(_gettext)\n",
        "    data['score_cat'] = data.score.apply(lambda _: _categorize(_, score_cats))\n",
        "    data['comment_cat'] = data.num_comments.apply(\n",
        "        lambda _: _categorize(_, comment_cats))\n",
        "    data['createdUTC'] = data.createdUTC.apply(\n",
        "        lambda x: dt.fromtimestamp(x, tz.utc))\n",
        "    return data\n",
        "\n",
        "\n",
        "def _categorize(val, cutoffs):\n",
        "    for level, upper_bound in enumerate(cutoffs):\n",
        "        if val < upper_bound:\n",
        "            return level + 1\n",
        "    return len(cutoffs) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UFgqL3nqX-h7",
        "colab_type": "code",
        "outputId": "e0f3428a-5dc1-4642-f88f-5a1e2247cb28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "train_dj = prepare_text(train_dj)\n",
        "test_dj = prepare_text(test_dj)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxVgH5nGMis8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dj.to_csv(base_path + 'train_dj.csv')\n",
        "test_dj.to_csv(base_path + 'test_dj.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iy62Aqr7lJS_",
        "colab": {}
      },
      "source": [
        "nlp = en_pytt_robertabase_lg.load(torchscript=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvxNsNrDbEw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textcat = nlp.create_pipe(\"pytt_textcat\", config={\"exclusive_classes\": True,\n",
        "                                                  'architecture': 'softmax_pooler_output',\n",
        "                                                  \"words_per_batch\": 1000})\n",
        "for label in range(1,6):\n",
        "    textcat.add_label(label)\n",
        "nlp.add_pipe(textcat, last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OiAju5vjHEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "131d5e91-39d0-4c32-8e03-3f4d2747af74"
      },
      "source": [
        "def check_pipe_config(nlp):\n",
        "  for p in nlp.pipe_names:\n",
        "    print(repr(p))\n",
        "    try:\n",
        "      print(nlp.get_pipe(p).cfg)\n",
        "    except:\n",
        "      pass\n",
        "    try:\n",
        "      print('model component included?:', nlp.get_pipe(p).model, '\\n')\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "check_pipe_config(nlp)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'sentencizer'\n",
            "'pytt_wordpiecer'\n",
            "{'deprecation_fixes': {'vectors_name': None}, 'pytt_name': 'roberta-base'}\n",
            "model component included?: <spacy_pytorch_transformers._tokenizers.SerializableRobertaTokenizer object at 0x7f254594b630> \n",
            "\n",
            "'pytt_tok2vec'\n",
            "{'deprecation_fixes': {'vectors_name': None}, 'pytt_name': 'roberta-base', 'pytt_config': {'finetuning_task': None, 'num_labels': 2, 'output_attentions': True, 'output_hidden_states': True, 'torchscript': False, 'vocab_size': 50265, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'type_vocab_size': 1, 'initializer_range': 0.02, 'layer_norm_eps': 1e-12, 'vocab_size_or_config_json_file': 50265}}\n",
            "model component included?: <thinc.neural._classes.function_layer.FunctionLayer object at 0x7f2543383358> \n",
            "\n",
            "'pytt_textcat'\n",
            "{'exclusive_classes': True, 'architecture': 'softmax_pooler_output', 'words_per_batch': 1000, 'labels': (1, 2, 3, 4, 5)}\n",
            "model component included?: True \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESRqT6kTvQy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dj = pd.read_csv(base_path + 'train_dj.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXnoTL9rX-iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def complete_joke(title, selftext):\n",
        "  if isinstance(selftext, str):\n",
        "    return ' '.join([title, selftext])\n",
        "  else:\n",
        "    return title\n",
        "\n",
        "train_texts = train_dj.apply(\n",
        "    lambda row: complete_joke(row['title_clean'], row['selftext_clean']), axis=1)\n",
        "#test_texts = test_dj.apply(\n",
        "#    lambda row: complete_joke(row['title_clean'], row['selftext_clean']), axis=1)\n",
        "\n",
        "TRAIN_DATA = list(zip(train_texts, [{\"cats\": {i: float(val==i) for i in range(1, 6)}} for val in train_dj['score_cat']]))\n",
        "#TEST_DATA = list(zip(test_texts, [{\"cats\": {i: float(val==i) for i in range(1, 6)}} for val in test_dj['score_cat']]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6CEQkfGNsXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(base_path + 'TRAIN.txt', 'w') as train:\n",
        "  for line in TRAIN_DATA:\n",
        "    train.write(str(line) + '\\n')\n",
        "with open(base_path + 'TEST.txt', 'w') as test:\n",
        "  for line in TEST_DATA:\n",
        "    test.write(str(line) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTPeUh7kOx1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "f5bfd8c0-5d84-4eff-86dc-409e195d2b04"
      },
      "source": [
        "check_gpu(is_using_gpu)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU!\n",
            "GPU Usage\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 12% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jiyZoetv9M3",
        "colab_type": "text"
      },
      "source": [
        "doc = nlp(train_texts[0], disable=['pytt_textcat'])\n",
        "print(doc)\n",
        "print([sent.text for sent in doc.sents])\n",
        "print(len([wp for wp in doc._.pytt_word_pieces_]), [wp for wp in doc._.pytt_word_pieces_])\n",
        "print(len(doc._.pytt_alignment), doc._.pytt_alignment)\n",
        "print(len(doc._.pytt_last_hidden_state), doc._.pytt_last_hidden_state)\n",
        "\n",
        "def spacy_alignment(doc):\n",
        "    print(\"After tokenization, this doc has {} tokens.\".format(len(doc)))\n",
        "    print(\"The part-of-speech tags are:\", [token.pos_ for token in doc])\n",
        "    if len(doc) < 10:\n",
        "        print(\"This is a pretty short document.\")\n",
        "    return doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh3JoQrQX-ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=5 #batch-szie changed to 4 to relieve pressure on GPU memory\n",
        "learn_rate=2e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZPQU6-TEPQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _cross_entropy(yHat, y):\n",
        "    if y == 1:\n",
        "      return -log(yHat)\n",
        "    else:\n",
        "      return -log(1 - yHat)\n",
        "\n",
        "def evaluate(nlp, texts, cats):\n",
        "    cross_ent = 0\n",
        "    correct = 0\n",
        "    total_words = sum(len(text.split()) for text in texts)\n",
        "    with tqdm(total=total_words, leave=False) as pbar:\n",
        "        i = 0\n",
        "        for doc in nlp.pipe(texts, batch_size=batch_size):\n",
        "            gold = cats[i]\n",
        "            for label, score in doc.cats.items():\n",
        "                if label not in gold:\n",
        "                    continue\n",
        "                cross_ent += _cross_entropy(score, gold[label])\n",
        "            if max(gold.keys(), key=(lambda x: gold[x])) == max(doc.cats.keys(), key=(lambda x: doc.cats[x])):\n",
        "                correct += 1\n",
        "            i += 1\n",
        "            pbar.update(len(doc.text.split()))\n",
        "    return correct / i * 100, cross_ent\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OC2Nx2wEzaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "f7413e27-2795-4869-c6ad-82cc6aeaec16"
      },
      "source": [
        "is_using_gpu = spacy.prefer_gpu()\n",
        "check_gpu(is_using_gpu)\n",
        "!nvidia-smi\n",
        "optimizer = nlp.resume_training()\n",
        "optimizer.alpha = 0.001\n",
        "optimizer.pytt_weight_decay = 0.005\n",
        "optimizer.L2 = 0.0\n",
        "learn_rates = cyclic_triangular_rate(\n",
        "    learn_rate / 3, learn_rate * 3, 2 * len(TRAIN_DATA) // batch_size\n",
        "    )\n",
        "print(\"Training the model...\")\n",
        "\n",
        "pbar = tqdm(total=100, leave=False)\n",
        "results = []\n",
        "epoch = 0\n",
        "step = 0\n",
        "eval_every = 100\n",
        "patience = 3\n",
        "while True:\n",
        "    # Train and evaluate\n",
        "    losses = defaultdict()\n",
        "    train_data, eval_data = train_test_split(TRAIN_DATA, test_size=0.2)\n",
        "    batches = minibatch(train_data, size=batch_size)\n",
        "    for batch in batches:\n",
        "        optimizer.pytt_lr = next(learn_rates)\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp.update(texts, annotations, sgd=optimizer, drop=0.1, losses=losses)\n",
        "        pbar.update(1)\n",
        "        if step and (step % eval_every) == 0:\n",
        "            pbar.close()\n",
        "            with nlp.use_params(optimizer.averages):\n",
        "                eval_texts, eval_annotations = zip(*eval_data)\n",
        "                accuracy, cross_ent = evaluate(nlp, eval_texts, eval_annotations)\n",
        "            results.append((cross_ent, accuracy, step, epoch))\n",
        "            print(\"{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"ACC\", \"CE\"))\n",
        "            print(\"{0:.3f}\\t{1:.3f}\\t{2:.3f}\".format(\n",
        "                losses[\"pytt_textcat\"], accuracy, total_ent\n",
        "                ))\n",
        "            pbar = tqdm(total=eval_every, leave=False)\n",
        "        step += 1\n",
        "    epoch += 1\n",
        "    print(f\"epoch {epoch}\")\n",
        "    # Stop if no improvement in HP.patience checkpoints\n",
        "    if results:\n",
        "        best_score, acc, best_step, best_epoch = max(results)\n",
        "        print(f\"best score: {best_score}  best_step : {best_step}  best epoch : {best_epoch} \")\n",
        "        print(f\"break clause: {((step - best_step) // eval_every)}\")\n",
        "        if ((step - best_step) // eval_every) >= patience:\n",
        "            break\n",
        "\n",
        "    msg = Printer()\n",
        "    table_widths = [2, 4, 6]\n",
        "    msg.info(f\"Best scoring checkpoints\")\n",
        "    msg.row([\"Epoch\", \"Step\", \"Score\"], widths=table_widths)\n",
        "    msg.row([\"-\" * width for width in table_widths])\n",
        "    for score, acc, step, epoch in sorted(results, reverse=True)[:10]:\n",
        "        msg.row([epoch, step, \"%.2f\" % (score * 100)], widths=table_widths)\n",
        "\n",
        "    # Test the trained model\n",
        "    test_text = eval_texts[0]\n",
        "    doc = nlp(test_text)\n",
        "    print(test_text, doc.cats)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU!\n",
            "GPU Usage\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 16% |\n",
            "Sun Sep  8 21:20:57 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    69W / 149W |   1886MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training the model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3bf798c02708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0meval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_ent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_annotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_ent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:^5}\\t{:^5}\\t{:^5}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LOSS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ACC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-4013a2d63207>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(nlp, texts, cats)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, texts, as_tuples, n_threads, batch_size, disable, cleanup, component_cfg)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0moriginal_strings_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mnr_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, stream, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mActivations\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0mper\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mActivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/model_registry.py\u001b[0m in \u001b[0;36msentence_fwd\u001b[0;34m(docs, drop)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0msents_per_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_per_doc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_per_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0macts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;31m# To go from \"per sentence\" activations to \"per doc\" activations, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# just have to tell it where the sequences end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/model_registry.py\u001b[0m in \u001b[0;36mapply_model_to_batches\u001b[0;34m(inputs, drop)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRaggedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mlh_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/wrapper.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, inputs, drop)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# \"drop is None\" indicates prediction. It's one of the parts of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Thinc's API I'm least happy with...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mmax_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mmodel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy_pytorch_transformers/wrapper.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"swap_swa_sgd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_swa_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"swap_swa_sgd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_swa_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    176\u001b[0m                            \u001b[0;34m\"This model requires special tokens in order to work. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                            \"Please specify add_special_tokens=True in your encoding.\")\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRobertaModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    708\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    709\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRJNYB5g7_vx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "cf02616a-40c1-4a36-e08e-4bc1cfb8657e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Sep  8 00:34:41 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    32W /  70W |   8097MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLvXnrz7I6hr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "354dbcbf-67c5-4481-d599-e9f5e55b6345"
      },
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemTotal:       13335184 kB\n",
            "MemFree:          477772 kB\n",
            "MemAvailable:    9887124 kB\n",
            "Buffers:           86396 kB\n",
            "Cached:          7495240 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          3774416 kB\n",
            "Inactive:        8561660 kB\n",
            "Active(anon):    2840376 kB\n",
            "Inactive(anon):    12608 kB\n",
            "Active(file):     934040 kB\n",
            "Inactive(file):  8549052 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               312 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       4754448 kB\n",
            "Mapped:           816860 kB\n",
            "Shmem:             13184 kB\n",
            "Slab:             295292 kB\n",
            "SReclaimable:     251764 kB\n",
            "SUnreclaim:        43528 kB\n",
            "KernelStack:        4432 kB\n",
            "PageTables:        17704 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6667592 kB\n",
            "Committed_AS:    7681068 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:           0 kB\n",
            "VmallocChunk:          0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "DirectMap4k:      184308 kB\n",
            "DirectMap2M:     7155712 kB\n",
            "DirectMap1G:     8388608 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPnLDXD0TpgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "4267d688-44c3-4629-cbcc-2cdbde2f33e4"
      },
      "source": [
        "!ps"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 run.sh\n",
            "      6 ?        00:00:04 node\n",
            "     22 ?        00:00:07 jupyter-noteboo\n",
            "    115 ?        00:00:00 tail\n",
            "    351 ?        00:03:18 python3\n",
            "    367 ?        00:00:00 python3\n",
            "    386 ?        00:00:00 drive\n",
            "    469 ?        00:00:02 drive\n",
            "    480 ?        00:00:00 fusermount <defunct>\n",
            "    517 ?        00:00:00 tail\n",
            "    518 ?        00:00:00 grep\n",
            "   1117 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J96xSp4gTsq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "a.append([1,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IewMRWzIQg5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "702bca47-e214-412e-e59b-8ab338e80219"
      },
      "source": [
        "a"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE6tFu-XQhhW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "9ccacdf5-2cb8-402c-8478-074732695d90"
      },
      "source": [
        "any((1,2,3) < 2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6f7618156967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'tuple' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y0VZkhHRCd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}